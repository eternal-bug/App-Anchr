[% INCLUDE header.tt2 %]

#----------------------------#
# Run
#----------------------------#

START_TIME=$(date +%s)
save START_TIME

NUM_THREADS=[% opt.parallel %]
save NUM_THREADS

BBTOOLS_RESOURCES=$(brew --prefix)/Cellar/$(brew list --versions bbtools | sed 's/ /\//')/resources
rm -f temp.fq.gz;

#----------------------------#
# Pipeline
#----------------------------#
# from bbmap/bbmap/pipelines/assemblyPipeline.sh

# Reorder reads for speed of subsequent phases
log_info "clumpify"
clumpify.sh \
    in=[% args.0 %] \
[% IF args.1 -%]
    in2=[% args.1 %] \
[% END -%]
    out=clumped.fq.gz \
    threads=[% opt.parallel %] \
    dedupe dupesubs=0 \
    overwrite
rm -f temp.fq.gz; ln -s clumped.fq.gz temp.fq.gz

[% FOREACH ecphase IN opt.ecphase -%]
log_info Error-correct phase [% ecphase %]

[% IF ecphase == 1 -%]
# Error-correct phase 1
# error-correct via overlap
bbmerge.sh \
    in=temp.fq.gz out=ecco.fq.gz \
    ihist=ihist.merge1.txt \
    threads=[% opt.parallel %] \
[% IF opt.prefilter -%]
    prefilter=[% opt.prefilter %]  \
[% END -%]
    ecco mix vstrict ordered overwrite
rm temp.fq.gz; ln -s ecco.fq.gz temp.fq.gz
[% END -%]

[% IF ecphase == 2 -%]
# Error-correct phase 2
clumpify.sh \
    in=temp.fq.gz out=eccc.fq.gz \
    threads=[% opt.parallel %] \
    passes=4 ecc unpair repair overwrite
rm temp.fq.gz; ln -s eccc.fq.gz temp.fq.gz
[% END -%]

[% IF ecphase == 3 -%]
# Error-correct phase 3
# Low-depth reads can be discarded here with the "tossjunk", "tossdepth", or "tossuncorrectable" flags.
# For large genomes, tadpole and bbmerge (during the "Merge" phase) may need the flag 
# "prefilter=1" or "prefilter=2" to avoid running out of memory.
# "prefilter" makes these take twice as long though so don't use it if you have enough memory.
tadpole.sh \
    in=temp.fq.gz out=ecct.fq.gz \
    threads=[% opt.parallel %] \
[% IF opt.prefilter -%]
    prefilter=[% opt.prefilter %]  \
[% END -%]
    ecc tossjunk tossdepth=2 tossuncorrectable ordered overwrite
rm temp.fq.gz; ln -s ecct.fq.gz temp.fq.gz
[% END -%]

[% END -%]

log_info "Read extension"
tadpole.sh \
    in=temp.fq.gz out=extended.fq.gz \
    threads=[% opt.parallel %] \
[% IF opt.prefilter -%]
    prefilter=[% opt.prefilter %]  \
[% END -%]
    ordered mode=extend el=20 er=20 k=62 overwrite
rm temp.fq.gz; ln -s extended.fq.gz temp.fq.gz

log_info "Read merging"
bbmerge-auto.sh \
    in=temp.fq.gz out=merged.fq.gz outu=unmerged.raw.fq.gz \
    ihist=ihist.merge.txt \
    threads=[% opt.parallel %] \
[% IF opt.prefilter -%]
    prefilter=[% opt.prefilter %]  \
[% END -%]
    strict k=81 extend2=80 rem overwrite

log_info "Quality-trim the unmerged reads"
bbduk.sh \
    in=unmerged.raw.fq.gz out=unmerged.trim.fq.gz \
    threads=[% opt.parallel %] \
    qtrim=r trimq=[% opt.qual %] minlen=[% opt.len %] overwrite

# Separates paired reads
repair.sh \
    in=unmerged.trim.fq.gz \
    out=U1.fq.gz \
    out2=U2.fq.gz \
    outs=Us.fq.gz \
    threads=[% opt.parallel %] \
    repair overwrite

# Create pe.cor.fa.gz
faops interleave \
    -p unmerged \
    U1.fq.gz \
    U2.fq.gz \
    > pe.interleave.fa

faops interleave \
    -p single \
    Us.fq.gz \
    >> pe.interleave.fa

faops interleave \
    -p merged \
    merged.fq.gz \
    >> pe.interleave.fa

#----------------------------#
# Shuffle interleaved reads.
#----------------------------#
log_info Shuffle interleaved reads.
cat pe.interleave.fa \
    | awk '{
        OFS="\t"; \
        getline seq; \
        getline name2; \
        getline seq2; \
        print $0,seq,name2,seq2}' \
    | shuf \
    | awk '{OFS="\n"; print $1,$2,$3,$4}' \
    > pe.cor.fa
rm pe.interleave.fa
pigz -p [% opt.parallel %] pe.cor.fa

log_debug "Reads stats with faops"
SUM_IN=$( faops n50 -H -N 0 -S [% args.0 %] [% IF args.1 %][% args.1 %][% END %])
save SUM_IN
SUM_OUT=$( faops n50 -H -N 0 -S pe.cor.fa.gz )
save SUM_OUT

#----------------------------#
# Done.
#----------------------------#
END_TIME=$(date +%s)
save END_TIME

RUNTIME=$((END_TIME-START_TIME))
save RUNTIME

log_info Done.

exit 0
